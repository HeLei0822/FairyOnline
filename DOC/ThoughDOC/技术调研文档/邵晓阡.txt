大数据数据库的设计方式，涉及的知识。

一、数据库的相关知识和数据库的设计。

1、把你表中经常查询的和不常用的分开几个表，也就是横向切分

2、把不同类型的分成几个表，纵向切分

3、常用联接的建索引

4、服务器放几个硬盘，把数据、日志、索引分盘存放，这样可以提高IO吞吐率

5、用优化器，优化你的查询

6、考虑冗余，这样可以减少连接

7、可以考虑建立统计表，就是实时生成总计表，这样可以避免每次查询都统计一次

8、用极量数据测试一下 数据仓库解决的是数据挖掘，共享，和大数据量存储有什么根本关系？

mrzxc 等说的好，考虑你的系统，注意负载平衡，查询优化，25 万并不大，可以建一个表，然后按mrzxc 的3 4 5 7 优化。 速度，影响它的因数太多了，且数据量越大越明显。

1、存储 将硬盘分成NTFS格式，NTFS比FAT32快，并看你的数据文件大小，1G以上你可以采用多数据库文件，这样可以将存取负载分散到多个物理硬盘或磁盘阵列上。

2、tempdb tempdb也应该被单独的物理硬盘或磁盘阵列上,建议放在RAID 0上，这样它的性能最高,不要对它设置最大值让它自动增长

3、日志文件 日志文件也应该和数据文件分开在不同的理硬盘或磁盘阵列上，这样也可以提高硬盘I/O性能。

4、分区视图 就是将你的数据水平分割在集群服务器上，它适合大规模OLTP,SQL群集上，如果你数据库不是访问特别大不建议使用。

5、簇索引 你的表一定有个簇索引，在使用簇索引查询的时候，区块查询是最快的，如用between，应为他是物理连续的，你应该尽量减少对它的updaet,应为这可以使它物理不连续。

6、非簇索引 非簇索引与物理顺序无关，设计它时必须有高度的可选择性，可以提高查询速度，但对表update的时候这些非簇索引会影响速度，且占用空间大，如果你愿意用空间和修改时间换取速度可以考虑。

7、索引视图 如果在视图上建立索引,那视图的结果集就会被存储起来，对与特定的查询性能可以提高很多，但同样对update语句时它也会严重减低性能，一般用在数据相对稳定的数据仓库中。

8、维护索引 你在将索引建好后，定期维护是很重要的，用dbcc showcontig来观察页密度、扫描密度等等，及时用dbcc indexdefrag来整理表或视图的索引,在必要的时候用dbcc dbreindex来重建索引可以受到良好的效果。 不论你是用几个表1、2、3点都可以提高一定的性能，5、6、8点你是必须做的，至于4、7点看你的需求，我个人是不建议的。打了半个多小时想是在写论文，希望对你有帮助。




二、可能会遇到的问题以及解决办法。

在高并发大数据量的访问情况下，我们的系统会不会出现极端的情况。(例如：对外统计系统在7月16日出现的数据异常的情况，并发大数据量的的访问造成，数据库的响应时间不能跟上数据刷新的速度造成。具体情况是：在日期临界时(00：00：00)，判断数据库中是否有当前日期的记录，没有则插入一条当前日期的记录。在低并发访问的情况下，不会发生问题，但是当日期临界时的访问量相当大的时候，在做这一判断的时候，会出现多次条件成立，则数据库里会被插入多条当前日期的记录，从而造成数据错误。)，数据库的模型确定下来之后，我们有必要做一个系统内数据流向图，分析可能出现的瓶颈。　　为了保证数据库的一致性和完整性，在逻辑设计的时候往往会设计过多的表间关联，尽可能的降低数据的冗余。(例如用户表的地区，我们可以把地区另外存放到一个地区表中)如果数据冗余低，数据的完整性容易得到保证，提高了数据吞吐速度，保证了数据的完整性，清楚地表达数据元素之间的关系。而对于多表之间的关联查询(尤其是大数据表)时，其性能将会降低，同时也提高了客户端程序的编程难度，因此，物理设计需折衷考虑，根据业务规则，确定对关联表的数据量大小、数据项的访问频度，对此类数据表频繁的关联查询应适当提高数据冗余设计但增加了表间连接查询的操作，也使得程序的变得复杂，为了提高系统的响应时间，合理的数据冗余也是必要的。设计人员在设计阶段应根据系统操作的类型、频度加以均衡考虑。　　另外，最好不要用自增属性字段作为主键与子表关联。不便于系统的迁移和数据恢复。对外统计系统映射关系丢失(******************)。　　原来的表格必须可以通过由它分离出去的表格重新构建。使用这个规定的好处是，你可以确保不会在分离的表格中引入多余的列，所有你创建的表格结构都与它们的实际需要一样大。应用这条规定是一个好习惯，不过除非你要处理一个非常大型的数据，否则你将不需要用到它。(例如一个通行证系统，我可以将USERID，USERNAME，USERPASSWORD，单独出来作个表，再把USERID作为其他表的外键)　　表的设计具体注意的问题：　　
1、数据行的长度不要超过8020字节，如果超过这个长度的话在物理页中这条数据会占用两行从而造成存储碎片，降低查询效率。　　

2、能够用数字类型的字段尽量选择数字类型而不用字符串类型的(电话号码)，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接回逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。　　

3、对于不可变字符类型char和可变字符类型varchar 都是8000字节,char查询快，但是耗存储空间，varchar查询相对慢一些但是节省存储空间。在设计字段的时候可以灵活选择，例如用户名、密码等长度变化不大的字段可以选择CHAR，对于评论等长度变化大的字段可以选择VARCHAR。　　

4、字段的长度在最大限度的满足可能的需要的前提下，应该尽可能的设得短一些，这样可以提高查询的效率，而且在建立索引的时候也可以减少资源的消耗。







三、封号、视频是否允许观看的审核机制是如制定的。

1、视频审核的工作一大部分由机器负责，除了规定所有用户自发上传的视频需要进行严格审查之外，网监还会对互联网上已经发布的视频进行二次审核。
2、在中国，每个公民都有一个唯一的身份证号(ID)，通过这个ID可以全方位的定位一个人的年龄、性别、出生地等，同比MD5就是视频的ID。网监有一个巨大的危险MD5库，库内藏着各种不能流于世的视频。视频网站都需要接入这个库，并在实际审核中增加自己的库存。
3、在早期，过滤视频的第一步就是横扫整个库，把MD5吻合的视频直接剔除，并将它提交给公安违禁库。
不过，匹配MD5正在逐步弃用，原因在于MD5非常容易被篡改，在视频中加入文字或者修改任意一帧就能实现。
于是，出现了更高级别的审核办法。
4、性能级:机器审核
通过MD5之后的视频，第二步会经历机器审核的过滤。市面上已经有成熟的第三方公司提供API接口，辅助视频网站进行机器审核。
5、机器审核视频是基于深度学习图像识别云，实际也是将视频截图，由机器审核每一张截图的安全性。不过具体是3秒截一张还是5秒截一张，松紧度由视频网站自己控制。
机器审核视频原理是先建模，然后导入海量的违禁视频，让多个机器同时进行深度样本学习，再标注无法通过的图像种类，进而把这些样本揉碎、旋转、添加“噪音”，提高机器识别能力。这其中拼的不止是技术，还有样本图库的大小。据了解，在图普科技的样本库中，有超过1亿的色情样本和千万级别的极端宗教主义样本特征。
6、对于不能通过的视频，机器审核视频会给出两类结果:确定不能通过的，这类的准确率几乎能达到99.5%以上;仅作参考的，准确率在95%到97%，这可能意味着该视频需要再次进行人工审核。
7、机器基本能筛过99%的视频，只有1%需要再次动用人工。如果是150万的视频，那人工只需要审核1.5万个。
8、目前视频网站的审核坐席基本都是7x24小时工作，在临近阅兵、六四等重要日子，还要加大审核人员的配置。对于机器没有通过的视频，审核的工作人员会把其每6秒截图，一页60张图，一眼扫过去就可以判别视频是否真的触了红线。
  总归就一点：人工看，重点用户重点监控！
